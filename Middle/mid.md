# 機器學習演算法
* 是一段程式碼，可協助使用者探索、分析並尋找複雜資料集中的意義。每種演算法都是一組有限的明確逐步指示，可讓電腦遵循，以達成特定目標。在機器學習模型中，目標是要建立或探索可讓使用者用於進行預測或分類資訊的模式
* 使用以訓練資料為基礎的參數，而所謂的訓練資料是代表較大型集合一組資料。隨著訓練資料的擴充而更真實地呈現世界時，演算法可計算出更精確的結果
* 不同演算法會以不同的方式來分析資料
* 通常依據其用於何種機器學習技術來分組：監督式學習、非監督式學習和增強式學習
* 可使用迴歸和分類來預測目標類別、找出不尋常的資料點、預測值，以及探索相似之處
* 機器學習中的具體方法或技術，用於訓練模型以從數據中學習並進行預測或決策。演算法是實現機器學習的工具，包括監督學習中的支持向量機、決策樹，以及無監督學習中的聚類算法等。

## 機器學習
1. 監督式學習（Supervised Learning）：
    * 簡介： 使用有標籤的數據進行訓練，其中每個輸入都有對應的輸出。
    * 例子： 線性回歸、支持向量機（SVM）、決策樹、隨機森林、神經網絡等。
    * 應用： 分類（Classification）、回歸（Regression）、物體檢測（Object Detection）等。

2. 非監督式學習（Unsupervised Learning）：
    * 簡介： 使用無標籤的數據進行訓練，模型需要自行發現數據中的結構和模式。
    * 例子： K均值聚類、層次聚類、主成分分析（PCA）、自編碼器（Autoencoders）等。
    * 應用： 聚類（Clustering）、降維（Dimensionality Reduction）、生成模型等。

3. 半監督式學習（Semi-Supervised Learning）：
    * 簡介： 同時使用有標籤和無標籤的數據進行訓練。
    * 應用： 當標籤數據相對較少時，可以通過半監督學習提高模型性能。

4. 強化學習（Reinforcement Learning）：
    * 簡介： 通過觀察環境和採取行動來學習最優策略，並通過獎勵信號進行反饋。
    * 應用： 遊戲玩家、機器人控制、金融交易等。

5. 深度學習（Deep Learning）：
    * 簡介： 使用多層神經網絡進行學習，尤其適用於大量數據和複雜任務。
    * 應用： 圖像識別、語音識別、自然語言處理等。

6. 遷移學習（Transfer Learning）：
    * 簡介： 將在一個任務上學習到的知識應用於另一個相關的任務上，通常能提高模型性能。

7. 集成學習（Ensemble Learning）：
    * 簡介： 將多個弱學習器組合成一個強學習器，例如隨機森林。

8. 支序列模型（Sequence Models）：
    * 簡介： 適用於處理時序數據，如循環神經網絡（RNN）和長短時記憶網絡（LSTM）。

9.生成對抗網絡（Generative Adversarial Networks，GANs）：
    * 簡介： 包括生成器和判別器，用於生成逼真的數據。

10. 自然語言處理（Natural Language Processing，NLP）：
    * 簡介： 應用於處理和理解人類語言，包括文本分類、命名實體識別等。

## 常見的機器學習演算法
1. 線性迴歸
線性迴歸可能是統計學和機器學習中最知名和最易理解的演算法之一
由於預測建模主要關注最小化模型的誤差，或者以可解釋性為代價來做出最準確的預測。 我們會從許多不同領域借用、重用和盜用演算法，其中涉及一些統計學知識

![](https://raw.githubusercontent.com/Chieh0622/alg112a/master/PIC/01_%E7%B7%9A%E6%80%A7%E5%9B%9E%E6%AD%B8.png)

3. 邏輯迴歸
邏輯迴歸是機器學習從統計領域借鑑的另一種技術。 這是二分類問題的專用方法（兩個類值的問題）
邏輯迴歸與線性迴歸類似，這是因為兩者的目標都是找出每個輸入變數的權重值。 與線性迴歸不同的是，輸出的預測值得使用稱為邏輯函式的非線性函式進行變換

![](https://raw.githubusercontent.com/Chieh0622/alg112a/master/PIC/02_%E9%82%8F%E8%BC%AF%E5%9B%9E%E6%AD%B8.png)

3. 貝氏機率分類
是一種簡單但極為強大的**預測建模**演算法
該模型由兩種型別的機率組成，可以直接從你的訓練資料中計算出來：1）每個類別的機率; 2）給定的每個x值的類別的條件機率。 一旦計算出來，機率模型就可以用於使用貝葉斯定理對新資料進行預測

![](https://raw.githubusercontent.com/Chieh0622/alg112a/master/PIC/03_%E8%B2%9D%E5%BC%8F%E6%A9%9F%E7%8E%87%E5%88%86%E9%A1%9E.png)

4. 支援向量機
超平面是分割輸入變數空間的線。 在SVM中，會選出一個超平面以將輸入變數空間中的點按其類別（0類或1類）進行分離。在二維空間中可以將其視為一條線，所有的輸入點都可以被這條線完全分開

![](https://raw.githubusercontent.com/Chieh0622/alg112a/master/PIC/04_%E6%94%AF%E6%8F%B4%E5%90%91%E9%87%8F%E6%A9%9F%E5%99%A8.png)

5. 決策樹
可用二叉樹表示是來自演算法和資料結構的二叉樹，每個節點代表單個輸入變數（x）和該變數上的左右孩子

![](https://raw.githubusercontent.com/Chieh0622/alg112a/master/PIC/05_%E6%B1%BA%E7%AD%96%E6%A8%B9.png)

6. K近鄰
透過搜尋整個訓練集內K個最相似的例項（鄰居），並對這些K個例項的輸出變數進行彙總，來預測新的資料點，新的點可能是平均輸出變數，對於分類問題，新的點可能是眾數類別值

![](https://raw.githubusercontent.com/Chieh0622/alg112a/master/PIC/06_K%E8%BF%91%E9%84%B0.png)

8. bagging和隨機森林
是**最流行和最強大**的機器學習演算法之一，它是一種被稱為Bootstrap Aggregation或Bagging的整合機器學習演算法
隨機森林是對決策樹的一種調整，相對於選擇最佳分割點，隨機森林透過引入隨機性來實現次優分割

![](https://raw.githubusercontent.com/Chieh0622/alg112a/master/PIC/07_%E9%9A%A8%E6%A9%9F%E6%A3%AE%E6%9E%97.png)

10. 梯度提升演算法
可產生預測模型，該模型可透過能改善模型整體效能的集體流程，結合弱式預測模型 (通常為決策樹)

![](https://raw.githubusercontent.com/Chieh0622/alg112a/master/PIC/08_%E6%A2%AF%E5%BA%A6%E4%B8%8A%E5%8D%87.png)

12. K-Means 演算法
可將資料分類為叢集，其中的 K 等於叢集數目。每個叢集內的資料點皆為同質，與其他叢集中的資料點則為異質

![](https://raw.githubusercontent.com/Chieh0622/alg112a/master/PIC/09_Kmeans.png)
